# Embedding / data ingestion ---------------------------------------------------

EMBED_DIM: 768                      # type: int | Must match embedding output dim (mpnet-base-v2 -> 768).
DEFAULT_INPUT_GLOB: "data/*.md"     # type: str | env override: VB_INPUT_GLOB
DEFAULT_CHUNKS_JSONL: "data/chunks.jsonl"  # type: str | env override: VB_CHUNKS_JSONL
DEFAULT_INPUT_JSONL: "data/chunks.jsonl"   # type: str | env override: VB_INPUT_JSONL
DEFAULT_COLLECTION: "docs"          # type: str | env override: VB_COLLECTION
DEFAULT_QUERY: "12. Are there any inconsistencies between the CAâ€™s declared scope of services (such as eSign, SSL, TSA, etc.) and the services for which compliance has been reported?"  # type: str | env override: VB_QUERY
DEFAULT_EMBED_MODEL: "sentence-transformers/all-mpnet-base-v2"             # type: str | env override: VB_EMBED_MODEL
FORCED_DEVICE: "cuda"                 # type: null|"cuda"|"cpu" | env override: VB_DEVICE

# LLM runtime ------------------------------------------------------------------

LLM_BASE_URL: "http://10.180.93.12:8007/v1"  # type: str | env override: LLM_BASE_URL
LLM_API_KEY: "EMPTY"                   # type: str | env override: LLM_API_KEY
LLM_MODEL: "openai/gpt-oss-20b"              # type: str | env override: LLM_MODEL
LLM_TEMPERATURE: 0.2                      # type: float | env override: LLM_TEMPERATURE
LLM_MAX_TOKENS: 2048                      # type: int | env override: LLM_MAX_TOKENS

# Chat history / feedback ------------------------------------------------------

CONV_ID: "default"               # type: str | env override: VB_CONV_ID
BRANCH_ID: "main"                # type: str | env override: VB_BRANCH_ID